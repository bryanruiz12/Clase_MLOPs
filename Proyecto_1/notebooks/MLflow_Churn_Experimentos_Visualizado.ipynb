{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a932617",
   "metadata": {},
   "source": [
    "# MLflow + Optuna + GridSearch para Churn (Telco)\n",
    "\n",
    "Este cuaderno demuestra cómo registrar experimentos en MLflow mientras se ajustan modelos como XGBoost, LightGBM y MLPClassifier usando GridSearchCV, RandomizedSearchCV y Optuna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d410c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879b133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset Telco\n",
    "url = 'https://raw.githubusercontent.com/blastchar/telco-churn/master/WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url)\n",
    "df = df.drop(columns=['customerID'])\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "df = df.dropna()\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "X = df.drop('Churn_Yes', axis=1)\n",
    "y = df['Churn_Yes']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a602019",
   "metadata": {},
   "source": [
    "## GridSearchCV con XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dac6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.05, 0.1]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), param_grid=params, cv=3)\n",
    "with mlflow.start_run(run_name='XGBoost GridSearch'):\n",
    "    grid.fit(X_train, y_train)\n",
    "    preds = grid.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    for param, val in grid.best_params_.items():\n",
    "        mlflow.log_param(param, val)\n",
    "    mlflow.log_metric('accuracy', acc)\n",
    "    mlflow.sklearn.log_model(grid.best_estimator_, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab46dc",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV con LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8940a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 300),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.2)\n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(LGBMClassifier(), param_distributions=param_dist, n_iter=10, cv=3)\n",
    "with mlflow.start_run(run_name='LightGBM RandomizedSearch'):\n",
    "    rand_search.fit(X_train, y_train)\n",
    "    preds = rand_search.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    for param, val in rand_search.best_params_.items():\n",
    "        mlflow.log_param(param, val)\n",
    "    mlflow.log_metric('accuracy', acc)\n",
    "    mlflow.sklearn.log_model(rand_search.best_estimator_, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30344f0e",
   "metadata": {},
   "source": [
    "## Optuna con MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e976e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [(64,), (128,), (64, 32)])\n",
    "    alpha = trial.suggest_float('alpha', 1e-5, 1e-2, log=True)\n",
    "    learning_rate_init = trial.suggest_float('learning_rate_init', 0.001, 0.1)\n",
    "\n",
    "    model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('mlp', MLPClassifier(max_iter=500, random_state=42, \n",
    "                              hidden_layer_sizes=hidden_layer_sizes,\n",
    "                              alpha=alpha, learning_rate_init=learning_rate_init))\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    return accuracy_score(y_test, preds)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "with mlflow.start_run(run_name='MLP Optuna'):\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    for k, v in study.best_params.items():\n",
    "        mlflow.log_param(k, v)\n",
    "    mlflow.log_metric('accuracy', study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014acdf0",
   "metadata": {},
   "source": [
    "## Visualización y Comparación de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe8d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "import seaborn as sns\n",
    "\n",
    "# Función para visualizar métricas de un modelo\n",
    "def evaluar_modelo(nombre, modelo, X_test, y_test):\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    y_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    print(f\"\\n{name}: AUC = {roc_auc:.3f}\")\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(f\"Matriz de Confusión - {nombre}\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'{nombre} (AUC = {roc_auc:.2f}')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    plt.xlabel('Tasa de Falsos Positivos')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos')\n",
    "    plt.title(f'Curva ROC - {nombre}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    sns.histplot(y_proba, kde=True, hue=y_test, bins=30)\n",
    "    plt.title(f'Distribución de probabilidades - {nombre}')\n",
    "    plt.xlabel('Probabilidad predicha')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación de modelos después del ajuste\n",
    "evaluar_modelo('XGBoost', grid.best_estimator_, X_test, y_test)\n",
    "evaluar_modelo('LightGBM', rand_search.best_estimator_, X_test, y_test)\n",
    "\n",
    "# Reconstruir MLP final con mejores parámetros\n",
    "from sklearn.pipeline import Pipeline\n",
    "best_mlp = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('mlp', MLPClassifier(max_iter=500, random_state=42, \n",
    "        hidden_layer_sizes=study.best_params['hidden_layer_sizes'],\n",
    "        alpha=study.best_params['alpha'],\n",
    "        learning_rate_init=study.best_params['learning_rate_init']))\n",
    "])\n",
    "best_mlp.fit(X_train, y_train)\n",
    "evaluar_modelo('MLP Optuna', best_mlp, X_test, y_test)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
